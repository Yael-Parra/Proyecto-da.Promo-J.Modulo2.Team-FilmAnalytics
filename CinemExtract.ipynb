{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto\n",
    "______________\n",
    "\n",
    "API: https://dev.adalab.es/cinema/\n",
    "Endpoint : https://dev.adalab.es/api/cinema/movies?year=2010&genre=Drama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías para su posterior uso en el código\n",
    "import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "from time import sleep\n",
    "pd.set_option('display.max_columns', None) # para poder visualizar todas las columnas de los DataFrames\n",
    "# Importar librerías de Selenium\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lista de años buscados: 15 años\n",
    "anio_lista = list(range(2009, 2025))\n",
    "\n",
    "# Lista de géneros\n",
    "generos_lista = [\"Drama\", \"Comedy\", \"Action\", \"Fantasy\", \"Horror\", \"Mystery\", \"Romance\", \"Thriller\"]\n",
    "\n",
    "# Lista vacía en la cual almacenaremos los datos extrañidos de la API\n",
    "datos_peliculas = []\n",
    "\n",
    "# Bucle para iterar por año y género\n",
    "for anio in anio_lista:\n",
    "    for genero in generos_lista:\n",
    "        # Determinar URL\n",
    "        url_movies = f\"https://dev.adalab.es/api/cinema/movies?year={anio}&genre={genero}\"\n",
    "        \n",
    "        # Llamada a API\n",
    "        res_url_movies = requests.get(url_movies)\n",
    "        \n",
    "        # Pausa para la API\n",
    "        sleep(1) \n",
    "        \n",
    "        # Verificar la espuesta de la API\n",
    "        if res_url_movies.status_code == 200:\n",
    "            try:\n",
    "                json_url_general = res_url_movies.json()\n",
    "                \n",
    "                # Imprimir jason para verlo\n",
    "                print(f\"Response for {anio} - {genero}: {json_url_general}\")\n",
    "                \n",
    "                # Verificar si la llamada tiene la info correcta\n",
    "                if isinstance(json_url_general, dict) and 'results' in json_url_general:\n",
    "                    movies = json_url_general['results']\n",
    "                    \n",
    "                    # Verificar que es lista\n",
    "                    if isinstance(movies, list):\n",
    "                        # Bucle por película para extraer info\n",
    "                        for pelicula in movies:\n",
    "                            id = pelicula.get(\"idOwner\")\n",
    "                            titulo = pelicula.get(\"title\")\n",
    "                            tipo = pelicula.get(\"type\")\n",
    "                            anio = pelicula.get(\"year\")\n",
    "                            genero = pelicula.get(\"genre\")\n",
    "                            \n",
    "                            # Añadir info a la lista anteriormente vacía\n",
    "                            datos_peliculas.append((id, titulo, tipo, anio, genero))\n",
    "                    else:\n",
    "                        print(\"Expected 'results' to be a list.\")\n",
    "                else:\n",
    "                    print(\"Expected JSON structure not found.\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error decoding JSON response.\")\n",
    "        else:\n",
    "            print(f\"Error: {res_url_movies.status_code} - {res_url_movies.reason}\")\n",
    "\n",
    "# Convertir a pandas frame\n",
    "df_peliculas = pd.DataFrame(datos_peliculas)\n",
    "\n",
    "# Salvar la busqueda en un documento con formato CSV\n",
    "df_peliculas.to_csv(\"movies_last_15_years.csv\", index=False)\n",
    "\n",
    "print(\"Data extraction complete and saved to movies_last_15_years.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datos_peliculas)\n",
    "print(type(datos_peliculas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene los nombres en la posición 2 (0,1,2) que es en donde está el type\n",
    "nombres_tipos = set(pelicula [2] for pelicula in datos_peliculas)\n",
    "print(\"Los tipos dentro de posición 2 son:\", nombres_tipos)\n",
    "\n",
    "# Crear listas vacías para cada tipo de película en minúsculas y añadir info con list comprehension\n",
    "tv_mini_series_lista = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"TV Mini Series\"]\n",
    "movie = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"Movie\"]\n",
    "tv_series = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"TV Series\"]\n",
    "short = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"Short\"]\n",
    "tv_episode = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"TV Episode\"]\n",
    "video = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"Video\"]\n",
    "tv_movie = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"TV Movie\"]\n",
    "video_game = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"Video Game\"]\n",
    "\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar el navegador\n",
    "driver = webdriver.Chrome()\n",
    "print(\"Abriendo Google\")\n",
    "# Maximizar la ventana del navegador\n",
    "driver.maximize_window()\n",
    "print(\"Pantalla maximizada\")\n",
    "sleep(3)\n",
    "\n",
    "# Abrir página web\n",
    "driver.get(\"https://www.imdb.com/\")\n",
    "print(\"Accediendo a la web\")\n",
    "sleep(3)\n",
    "\n",
    "# Aceptar cookies\n",
    "driver.find_element(\"css selector\", \"#__next > div > div > div.sc-jrcTuL.bPmWiM > div > button.icb-btn.sc-bcXHqe.sc-dkrFOg.sc-iBYQkv.dcvrLS.ddtuHe.dRCGjd\").click()\n",
    "print(\"Cookies aceptadas\")\n",
    "sleep(5)\n",
    "\n",
    "# Diccionario vacío en dónde se almacenarán los datos\n",
    "datos_imdb = {\"puntuacion\":[], \"direccion\":[], \"guionista\":[], \"argumento\":[], \"nombre_pelicula\":[], \"id_pelicula\":[]}\n",
    "\n",
    "# Obtiene los nombres en la posición 2 (0,1,2) que es en donde está el type\n",
    "nombres_tipos = set(pelicula [2] for pelicula in datos_peliculas)\n",
    "print(\"Los tipos dentro de posición 2 son:\", nombres_tipos)\n",
    "\n",
    "# Crear listas vacías para cada tipo de película en minúsculas y añadir info con list comprehension\n",
    "tv_mini_series_lista = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"TV Mini Series\"]\n",
    "movie = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"Movie\"]\n",
    "tv_series = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"TV Series\"]\n",
    "short = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"Short\"]\n",
    "tv_episode = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"TV Episode\"]\n",
    "video = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"Video\"]\n",
    "tv_movie = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"TV Movie\"]\n",
    "video_game = [pelicula for pelicula in datos_peliculas if pelicula[2].replace('_', ' ') == \"Video Game\"]\n",
    "\n",
    "# Iterar sobre los IDs de las películas\n",
    "id_pelicula = [pelicula[0] for pelicula in movie]\n",
    "\n",
    "\n",
    "for id_pelicula in id_pelicula:\n",
    "    url_pelicula = f\"https://www.imdb.com/title/{id_pelicula}/\"\n",
    "\n",
    "    # Navegar a la página de la película usando el ID\n",
    "    driver.get(url_pelicula)\n",
    "    sleep(5)\n",
    "\n",
    "    try:\n",
    "        # Extraer el nombre de la película\n",
    "        titulo = driver.find_element(\"css selector\", \"h1 span\").text\n",
    "        datos_imdb[\"nombre_pelicula\"].append(titulo)\n",
    "        datos_imdb[\"id_pelicula\"].append(id_pelicula)\n",
    "        print(f\"Titulo: {titulo}\")\n",
    "        \n",
    "        # Extraer la puntuación\n",
    "        try:\n",
    "            puntuacion = driver.find_element(\"css selector\", \"span.sc-eb51e184-1.ljxVSS\").text\n",
    "            datos_imdb[\"puntuacion\"].append(puntuacion)\n",
    "            print(f\"Puntuacion: {puntuacion}\")\n",
    "        except:\n",
    "            datos_imdb[\"puntuacion\"].append(\"N/A\")\n",
    "            print(\"Puntuación no encontrada\")\n",
    "        \n",
    "        # Extraer la dirección\n",
    "        try:\n",
    "            directores = driver.find_element(\"CSS selector\", '#__next > main > div > section.ipc-page-background.ipc-page-background--base.sc-afa4bed1-0.iMxoKo > section > div:nth-child(5) > section > section > div.sc-491663c0-4.gxWIhN > div.sc-491663c0-6.etrlfo > div.sc-491663c0-10.iaQXlA > section > div.sc-1f50b7c-3.gLpgJQ > div > ul > li:nth-child(1) > div > ul > li > a').text\n",
    "            datos_imdb[\"direccion\"].append(directores)\n",
    "            print(f\"Dirección: {directores}\")\n",
    "        except:\n",
    "            datos_imdb[\"direccion\"].append(\"N/A\")\n",
    "            print(\"Dirección no encontrada\")\n",
    "\n",
    "        #Extraer guionista\n",
    "        try:\n",
    "            guionista = driver.find_element(\"CSS selector\", '#__next > main > div > section.ipc-page-background.ipc-page-background--base.sc-afa4bed1-0.iMxoKo > section > div:nth-child(5) > section > section > div.sc-491663c0-4.ILcwq > div.sc-491663c0-6.bvzCJs > div.sc-491663c0-11.hFWIYv > div.sc-1f50b7c-2.cpicUu > div > ul > li:nth-child(2) > div > ul').text\n",
    "            datos_imdb[\"guionista\"].append(guionista)\n",
    "            print(f\"Guionista: {guionista}\")\n",
    "        except:\n",
    "            datos_imdb[\"guionista\"].append(\"N/A\")\n",
    "            print(\"Guionista no encontrado\")\n",
    "\n",
    "        #Extraer argumento\n",
    "        try:\n",
    "            argumento = driver.find_element(\"CSS selector\", 'p span').text\n",
    "            datos_imdb[\"argumento\"].append(argumento)\n",
    "            print(f\"Argumento: {argumento}\")\n",
    "        except:\n",
    "            datos_imdb[\"argumento\"].append(\"N/A\")\n",
    "            print(\"Argumento no encontrado\")\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar la película con ID '{id_pelicula}': {e}\")\n",
    "        datos_imdb[\"nombre_pelicula\"].append(\"N/A\")\n",
    "        datos_imdb[\"id_pelicula\"].append(id_pelicula)\n",
    "        datos_imdb[\"puntuacion\"].append(\"N/A\")\n",
    "        datos_imdb[\"direccion\"].append(\"N/A\")\n",
    "        # (Añadir \"N/A\" o valores por defecto para otros campos si es necesario)\n",
    "\n",
    "print(datos_imdb)\n",
    "# Cerrar el navegador\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **EXTRACCION ACTORES** \n",
    "\n",
    "Instertar aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL de la página de Wikipedia\n",
    "url_oscar = \"https://es.wikipedia.org/wiki/Premios_%C3%93scar\"\n",
    "\n",
    "# Realizar la solicitud HTTP a la página\n",
    "res_url_oscar = requests.get(url_oscar)\n",
    "\n",
    "# Verificar si la solicitud fue exitosa\n",
    "if res_url_oscar.status_code == 200:\n",
    "    # Parsear el contenido HTML con BeautifulSoup\n",
    "    sopa_oscar = BeautifulSoup(res_url_oscar.content, \"html.parser\")\n",
    "\n",
    "    # dict vacío en dónde se almacenarán los datos encontrados\n",
    "    dict_datos_oscar = {\"Ceremonia\": [], \"Mejor película\": [], \"Mejor director\": [], \"Mejor actor\": [], \"Mejor actriz\": []}\n",
    "\n",
    "    # Extraemos los datos de, únicamente la tabla dada.\n",
    "    tabla_oscar = sopa_oscar.select_one(\"#mw-content-text .wikitable\")\n",
    "    # css selector COMPLETO: #mw-content-text > div.mw-content-ltr.mw-parser-output > table.wikitable\n",
    "    # El selector se ha simplificado en caso de haber tablas anidadas. Y PORQUE CON EL COMPLETO NO NOS SALÍA ...... \n",
    "    \n",
    "    # Crear una lista vacía para almacenar las tuplas\n",
    "    lista_tuplas_oscar = []\n",
    "\n",
    "    # Verificar que la tabla haya sido extraída correctamente\n",
    "    if tabla_oscar:\n",
    "        # Iterar sobre la tabla buscando las filas (Inspeccionando la web, vemos que las filas están en tr)\n",
    "        filas = tabla_oscar.find_all('tr')\n",
    "        \n",
    "        # Iterando sobre las filas encontradas dentro de la tabla\n",
    "        for fila in filas[1:]:  # La primera fila es el encabezdo que no necesitamos.\n",
    "            \n",
    "            celdas = fila.find_all('td') # Inspeccionando la web, vemos que en td, está el contenido de las celdas\n",
    "            if len(celdas) >= 6: # Hay que revisar la cantidad de posiciones que tenemos\n",
    "                \n",
    "                fecha_divida = ceremonia.split() # dividir el texto\n",
    "\n",
    "                fecha_anio = fecha_divida[-1]\n",
    "                anio = int(fecha_anio)\n",
    "\n",
    "\n",
    "                if anio >= 2000:\n",
    "                    # Extraer contenido de celdas por posición/ index \n",
    "                    ceremonia = celdas[1].text.strip() #extraemos por index y sólo el texto y sin espacios extras\n",
    "                    mejor_pelicula = celdas[2].text.strip()\n",
    "                    mejor_director = celdas[3].text.strip()\n",
    "                    mejor_actor = celdas[4].text.strip()\n",
    "                    mejor_actriz = celdas[5].text.strip()\n",
    "                    \n",
    "                    # Añadir los datos al diccionario\n",
    "                    dict_datos_oscar[\"Ceremonia\"].append(fecha_divida[-1]) #que solo nos traiga la última posición ya que coresponde al año\n",
    "                    dict_datos_oscar[\"Mejor película\"].append(mejor_pelicula)\n",
    "                    dict_datos_oscar[\"Mejor director\"].append(mejor_director)\n",
    "                    dict_datos_oscar[\"Mejor actor\"].append(mejor_actor)\n",
    "                    dict_datos_oscar[\"Mejor actriz\"].append(mejor_actriz)\n",
    "\n",
    "                    # Creamos una tupla con los datos extraídos de cada fila de la tabla y se añaden a la lista de tuplas (\"lista_tuplas_oscar\")\n",
    "                    tupla = (fecha_divida, mejor_pelicula, mejor_director, mejor_actor, mejor_actriz)\n",
    "                    lista_tuplas_oscar.append(tupla)\n",
    "\n",
    "            # Comprobando que el display sea el máximo para mostrar mejor el data frame\n",
    "            pd.set_option('display.max_rows', 100)  # Cambia el número máximo de filas mostradas\n",
    "            pd.set_option('display.max_columns', 10)  # Cambia el número máximo de columnas mostradas\n",
    "            pd.set_option('display.width', 1000)  # Cambia el ancho máximo de la pantalla\n",
    "\n",
    "            # Convertir el diccionario en un DataFrame de pandas\n",
    "            df_oscar = pd.DataFrame(dict_datos_oscar)\n",
    "\n",
    "            # Mostrar el DataFrame\n",
    "            print(df_oscar)\n",
    "\n",
    "         # Iterar y printar cada tupla de la lista de tuplas (\"lista_tuplas_oscar\")\n",
    "        print(\"Lista de tuplas:\")\n",
    "        for tupla in lista_tuplas_oscar:\n",
    "            print(tupla)\n",
    "\n",
    "    else:\n",
    "        print(\"No se ha encontrado la tabla 'wikitable'\")\n",
    "else:\n",
    "    print(f\"Error al acceder a la página: {res_url_oscar.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
